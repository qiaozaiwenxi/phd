\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage[breaklinks=true,hidelinks]{hyperref}
% \usepackage[breaklinks=true]{hyperref}
% \usepackage[xindy, toc, nonumberlist]{glossaries}
\usepackage[toc, nonumberlist]{glossaries}
% \gls{label} to invoke the entry.
% \glsreset{label} to reset the first occurence of the entry.
% \acrlong{label} to print the long version of the acronym.
% \acrshort{label} to print the short version of the acronym.

\usepackage[]{natbib}
% \usepackage[numbers]{natbib}
\usepackage{amsthm}%theorems
\newtheoremstyle{customdef}%
	{\topsep}% above the theorem
	{\topsep}% below the theorem
	{\itshape}% body
	{0pt}% indent
	{\bfseries}% head
	{\newline}% punctuation between head and body
	{ }% Space after theorem head
	{\thmname{#1}\thmnumber{ #2}: \thmnote{#3}}
\theoremstyle{customdef}
\newtheorem{definition}{Definition}


\makeglossaries
\include{glossary}

% \author{Quentin Delhaye}
% \date{October 25th, 2015}
\title{State of the Art}

\begin{document}
\maketitle
\tableofcontents





% ######     #########  #########  ########   ##      ##  ########   ##########  ########     #####    ##      ##  
% ##    ##   ##         ##            ##      ###     ##     ##          ##         ##      ##     ##  ###     ##  
% ##     ##  ##         ##            ##      ## ##   ##     ##          ##         ##      ##     ##  ## ##   ##  
% ##     ##  ######     ######        ##      ##  ##  ##     ##          ##         ##      ##     ##  ##  ##  ##  
% ##     ##  ##         ##            ##      ##   ## ##     ##          ##         ##      ##     ##  ##   ## ##  
% ##    ##   ##         ##            ##      ##     ###     ##          ##         ##      ##     ##  ##     ###  
% ######     #########  ##         ########   ##      ##  ########       ##      ########     #####    ##      ##  


\section{Big words, big definitions}





%   #####    ##     ##  #########   #######   ##########  ########     #####    ##      ##  
% ##     ##  ##     ##  ##         ##     ##      ##         ##      ##     ##  ###     ##  
% ##     ##  ##     ##  ##         ##             ##         ##      ##     ##  ## ##   ##  
% ##     ##  ##     ##  ######      #######       ##         ##      ##     ##  ##  ##  ##  
% ##    # #  ##     ##  ##                ##      ##         ##      ##     ##  ##   ## ##  
%   #### #   ##     ##  ##         ##     ##      ##         ##      ##     ##  ##     ###  
%         #   #######   #########   #######       ##      ########     #####    ##      ##  


\section{Questions}
\subsection{Why do we even bother with hypergraphs?}
All hypergraphs can be represented as regular graphs, and lots of tools already exists to handle graphs.
When we want to express the wire length between two nodes, although it can easily be done using graph's edge weights, it is not expressable as a hypergraph's hyperedge weight, the hyperedge linking several nodes all connected with different wire lengths.

However, when tackling the partitioning problem, working with hypergraphs gives the vertices belonging to the same hyperedge a coherence.
In the context of 3D ICs, we work with buses connecting blocks of gates, and we want them to be handled as such.

Moreover, \citet{Ihler1993} demonstrated that the mincut partition obtained for a circuit is not as accurate as would be a hypergraph's.
More precisely, they define a \textit{cut-model} in definitions~\ref{def:cut-model} and \ref{def:cut-model-formal}, and show that there is no such thing in general.

\begin{definition}[Cut-model]\label{def:cut-model}
An edge-weighted graph $(V,E)$ is a cut-model for an edge-weighted hypergraph $(V,H)$ if the weight of the edges cut by any bipartition of $V$ in the graph is the same as the weight of the hyperedges cut by the same bipartition in the hypergraph.
\end{definition}

A more formal way to define the principle is as follows~:
\begin{definition}[Cut-model and mincut-model]\label{def:cut-model-formal}
A graph $(V, E)$ on $k$ vertices is a cut-model (for a unit weight hyperedge on $k$ vertices) if the weight of any cut induced by a non-empty proper subset $W$ of $V$ is equal to one.

A graph $(V \cup D,E)$ on $k+d$ vertices is called a min-cut-model (for a unit weight hyperedge on $k$ vertices) if for every non-empty subset $W$ of $V$ we have that the weight of any cut with minimum weight (mincut) under those separating $W$ from $V \setminus W$ is equal to one.
It must be zero fo $W=\emptyset$.%Note: other symbol for empty set: \varnothing
\end{definition}






% ##      ##    #####    ##########  ########     #####    ##      ##   #######   
% ###     ##  ##     ##      ##         ##      ##     ##  ###     ##  ##     ##  
% ## ##   ##  ##     ##      ##         ##      ##     ##  ## ##   ##  ##         
% ##  ##  ##  ##     ##      ##         ##      ##     ##  ##  ##  ##   #######   
% ##   ## ##  ##     ##      ##         ##      ##     ##  ##   ## ##         ##  
% ##     ###  ##     ##      ##         ##      ##     ##  ##     ###  ##     ##  
% ##      ##    #####        ##      ########     #####    ##      ##   #######   


\section{Recurring notions}
\subsection{Complexity}


\subsubsection{Non-deterministic Turing Machine}
In this kind of Turing machines, the transition \textit{rule} becomes a transition \textit{function}.
It means that at a given state, with a given symbol, it has many possible execution instead of just the one with a deterministic Turing machine.
We can see that as the machine always taking the best possible guess, leading to a finishing state in the end, or the machine is branching into all the possible states from the point of decision.

\subsubsection{NP}
Acronym for ``non-deterministic polynomial-time".
A ``yes"-instance can be found in polynomial-time by a non-deterministic Turing machine, and this solution can be verified in polynomial-time by a deterministic Turing machine.


\subsubsection{NP Hard}
Acronym for ``non-deterministic polynomial-time hard".
~\newline{}\noindent Note: it has never been proven that there is no polynomial-time algorithm to solve those problems.
Informally, it means that those problems are at least as hard as the hardest problems in NP.

\subsubsection{NP Complete}
A problem is NP complete when it is both NP and NP hard at the same time.
Although the solution can be verified in polynomial time, there is no known algorithm to find this solution quickly.
The problem to know if such algorithm exist is the ``P $=$ NP" problem.

An NP-complete problem differs from a regular NP problem in the sense that a problem is NP-complete if every other problem in NP can be reduced to it.ea

\subsubsection{P=NP}
Problem asking if there exist polynomial time algorithm solving NP-complete problems (an by corollary all NP problems).

\subsection{Optimization}

\subsubsection{Linear Programming}
Optimization of a problem for which the requirements are represented using linear relationships.

\subsubsection{Semidefinite Programming}
Extends the linear programming problems, but using a positive semidefinite matrix as unknown value, instead of a vector of real integers.






% ########      ###     ########   ##########  ########   ##########  ########     #####    ##      ##  ########   ##      ##   #######   
% ##     ##    ## ##    ##     ##      ##         ##          ##         ##      ##     ##  ###     ##     ##      ###     ##  ##         
% ##     ##   ##   ##   ##     ##      ##         ##          ##         ##      ##     ##  ## ##   ##     ##      ## ##   ##  ##         
% #######    ##     ##  ########       ##         ##          ##         ##      ##     ##  ##  ##  ##     ##      ##  ##  ##  ##   ####  
% ##         #########  ##   ##        ##         ##          ##         ##      ##     ##  ##   ## ##     ##      ##   ## ##  ##     ##  
% ##         ##     ##  ##    ##       ##         ##          ##         ##      ##     ##  ##     ###     ##      ##     ###  ##     ##  
% ##         ##     ##  ##     ##      ##      ########       ##      ########     #####    ##      ##  ########   ##      ##  ########   


\section{Graph Partitioning}
For a graph $G = (V, E)$, with $V$ the set of $n$ vertices and $E$ the set of edges.

\subsection{Balanced partition problem}
In a $(k, v)$ balanced partition problem, we want to partition $G$ into $k$ partitions of at most size $v\cdot\frac{n}{k}$, minimizing the capacity of the edges spanning multiple partitions~\cite{Andreev:2004:BGP:1007912.1007931}.
This could allow to perform unbalanced paritioning based on the factor $v$; if $v = 1$, all partitions will have the same size (considering $v \in \mathbb{N}_0$).
However, it is still an upper bound, not an objective.
All the partitions will have the same freedom in size, this does not enforce an asymmetry in the partitions size.
This problem is also know as bicriteria approximation or ressource augmentation.
While we are talking about vocabulary, when $k=2$, we have a \textit{bipartition problem}, and if $k>2$, we are proceeding to a \textit{k-way partitioning}.

\subsection{Algorithms}
\cite{SungKyuLim:ECE6133:partitioning}, \cite{Lim2008}
\subsubsection{Kernighan-Lin Algorithm~\citep*{Kernighan1970}}

\subsubsection{Fiduccia-Mattheyses Algorithm~\citep*{Fiduccia1982}}

\subsubsection{EIG Algorithm~\citep*{Hagen1992}}
\citet{Hagen1992} showed that the second smallest eigenvalue of the connectivity matrix of the graph is a tight lower bound on the ratio cut metric.
That metric is defined as $\frac{c(X,Y)}{|X||Y|}$ with $c(X, Y)$ the cutsize between the two partitions.

Based on this result, they built an algorithm to make bipartition of graphs with minimal ratio cut.

The idea is first to approximate the hypergraph with an undirected graph using a $k$-clique model.
This model states that a clique with k nodes forms a $k$-clique, hence a hyperedge forms one as well.
From this graph, we derive the degree matrix $D$ where  $d_{ii}$ is the sum of all the weights of the incident edges on node $i$.
Similarly, we build the adjacent matrix $A$ where $a_{ij}$ gives the weight of the edge $(i, j)$.
The Laplacian matrix $Q$ is then $Q = D - A$, from which we extract the eigenvector and its second smallest value.
Using the ordered eigenvector, we then compute $n-1$ partitionings: $(\{v_1\}, \{v_2, ..., v_n\}), (\{v_1, v_2\}, \{v_3, ..., v_n\}), ..., (\{v_1, ..., v_{n-1}\}, \{v_n\})$.

In the end, this method is particularly useful to set a lower bound on the ratio cut.


\subsubsection{FBB Algorithm~\citep*{Yang1996}}

\subsection{Metaheuristics}

\paragraph{Local Search Strategy}
A local search will look in the neighbourhood of the current solution for a better one.
If there is nothing better in the direct vicinity of the position, just stop.
As \cite{Pirlot1996} says, this trategy is also known as ``descent" strategy and is basically what was done in \texttt{phoney} when we tried to disbalance the energy repartition in the partitions, while keeping the area balanced.

The problem of this strategy is that it will get stuck in local minima.
Escaping requires a deterioration of the solution, which is done by \gls{sa} and \gls{ts}.

\subsubsection{Simulated Annealing}
\cite{Pirlot1996} presents this heuristic kind of like the evolution of a local search.
Instead of looking in the neighbourhood of the current solution, we pick one randomly.
If it's better, keep it, otherwise we have a probabilty $p$ to keep it, $(1-p)$ to discard it.
$p$ is usually a Boltzmann-like distribution:
\[p(n) = \exp{\left(-\frac{1}{T(n)} \Delta F_n\right)}\]
with $n$ the current step, $\Delta F_n = F(x) - F(x_n)$ the distance from the current solution, and $T(n)$ is what we could call the ``temperature" by analogy with the annealing of steel.
Each $L$ steps, the temperature decreases, lowering the probability to accept a worse solution.

The stopping condition can be a number of steps from the begining or a number a steps without enough improvement of the solution.

\subsubsection{Tabu Search}
A \acrlong{ts}, as its name and \cite{Pirlot1996} indicate, is based on a tabu of some sort.
We will proceed like for a regular local search, the difference being that we establish a tabu list that prevents from cycling through the same solutions.
In this list, we could simply store the $L$ last visited solutions, forbidding them.
But this is still not good enough and performs poorly in practice.
An other approach is the forbid \textit{movements}, \textit{e.g.} changing some coordinate from $0$ to $1$.
However, should a potential solution forbidden by the tabu list be so good according to some ``aspiration level", the tabu can be overlooked and the solution be chosen.

\subsubsection{Genetic Algorithms}






% ##       ##     ###     ##      ##  ##     ##  #########     ###      #######   ##########  ##     ##  ########   ########   ##      ##   #######   
% ###     ###    ## ##    ###     ##  ##     ##  ##           ## ##    ##     ##      ##      ##     ##  ##     ##     ##      ###     ##  ##         
% ## ## ## ##   ##   ##   ## ##   ##  ##     ##  ##          ##   ##   ##             ##      ##     ##  ##     ##     ##      ## ##   ##  ##         
% ##  ###  ##  ##     ##  ##  ##  ##  ##     ##  ######     ##     ##  ##             ##      ##     ##  ########      ##      ##  ##  ##  ##   ####  
% ##       ##  #########  ##   ## ##  ##     ##  ##         #########  ##             ##      ##     ##  ##   ##       ##      ##   ## ##  ##     ##  
% ##       ##  ##     ##  ##     ###  ##     ##  ##         ##     ##  ##     ##      ##      ##     ##  ##    ##      ##      ##     ###  ##     ##  
% ##       ##  ##     ##  ##      ##   #######   ##         ##     ##   #######       ##       #######   ##     ##  ########   ##      ##  ########   


\section{Manufacturing}

\subsection{Wafer to wafer}

\subsection{Die to die}

\subsection{Die to wafer}

\subsection{Monolithic}





% #########  ######        ###     
% ##         ##    ##     ## ##    
% ##         ##     ##   ##   ##   
% ######     ##     ##  ##     ##  
% ##         ##     ##  #########  
% ##         ##    ##   ##     ##  
% #########  ######     ##     ##  


\section{Electronic Design Automation}
EDA is also known as ``Electronic Computer-Aided Design" (ECAD).

\subsection{Conferences}
\subsubsection{Design Automation Conference}
San Diego, Anaheim and San Francisco in June.
\subsubsection{International Conference on computer-Aided Design}
\subsubsection{Design Automation an Test in Europe}
\subsubsection{Asia and South Pacific Design Automation Conference}
\subsubsection{International Symposium on Quality Electronic Design}







% ########   #########    #####    ########   ##         #########  
% ##     ##  ##         ##     ##  ##     ##  ##         ##         
% ##     ##  ##         ##     ##  ##     ##  ##         ##         
% #######    ######     ##     ##  #######    ##         ######     
% ##         ##         ##     ##  ##         ##         ##         
% ##         ##         ##     ##  ##         ##         ##         
% ##         #########    #####    ##         #########  #########  


\section{Big names for big problems}

\begin{description}

	\item{Andrew B. Kahng}

	\item{Charles J. Alpert}

	\item{Sung Kyu Lim}

	\item{Georges Karypis}

	\item{Shawki Areibi}
	Tabu search and EIG-tabusearch fusion.
\end{description}

\newpage

\glsaddall
\printglossaries

\newpage
\bibliographystyle{abbrvnat}
% \bibliographystyle{acm}
\bibliography{../thesis/bibliography.bib}

\end{document}
